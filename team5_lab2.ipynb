{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models\t50\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as ny\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os \n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e7971309563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_business_eda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/Documents/yelp_datasets/df_business_eda.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "df_business_eda = pd.read_pickle(\"~/Documents/yelp_datasets/df_business_eda.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/site-packages (0.0.11)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle5\n",
    "import socket\n",
    "import pickle5 as pickle\n",
    "\n",
    "is_rohit=socket.gethostname()=='Rohits-MacBook-Pro.local'\n",
    "\n",
    "if(is_rohit):\n",
    "    with open('~/Documents/yelp_datasets/df_business_eda.pickle', \"rb\") as f:\n",
    "      pick_data = pickle.load(f)\n",
    "      pick_data.to_pickle('~/Documents/yelp_datasets/df_business_eda_proto4.pickle')\n",
    "\n",
    "    df_business_eda = pd.read_pickle(\"~/Documents/yelp_datasets/df_business_eda_proto4.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=df_business_eda.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_business_hot=df_business_eda\n",
    "\n",
    "for col in categorical_cols:\n",
    "    dummies=pd.get_dummies(df_business_hot[col], dummy_na=True, prefix=col)\n",
    "    df_business_hot=df_business_hot.\\\n",
    "        drop(col,axis=1).\\\n",
    "    merge(\n",
    "        dummies,\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "        )\n",
    "    \n",
    "df_business_hot=df_business_hot.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_business_hot.rating_category\n",
    "X=df_business_hot.drop([\"rating_category\", \"stars\"], axis=1)\n",
    "\n",
    "x_train,x_test,y_train,y_test=ms.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original dataset : (99887, 276)\n",
      "shape of input - training set (79909, 274)\n",
      "shape of output - training set (79909,)\n",
      "shape of input - testing set (19978, 274)\n",
      "shape of output - testing set (19978,)\n"
     ]
    }
   ],
   "source": [
    "#printing shapes of testing and training sets :\n",
    "print(\"shape of original dataset :\", df_business_hot.shape)\n",
    "print(\"shape of input - training set\", x_train.shape)\n",
    "print(\"shape of output - training set\", y_train.shape)\n",
    "print(\"shape of input - testing set\", x_test.shape)\n",
    "print(\"shape of output - testing set\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stoichastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = ms.ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration Multinomial 0 ====\n",
      "accuracy: 0.5829912904194614\n",
      "confusion matrix:\n",
      " [[1198  716 2184]\n",
      " [ 650 1324 3568]\n",
      " [ 448  765 9125]]\n",
      "====Iteration Multinomial 1 ====\n",
      "accuracy: 0.5780358394233657\n",
      "confusion matrix:\n",
      " [[1179  712 2182]\n",
      " [ 666 1316 3690]\n",
      " [ 461  719 9053]]\n",
      "====Iteration Multinomial 2 ====\n",
      "accuracy: 0.582390629692662\n",
      "confusion matrix:\n",
      " [[1201  716 2104]\n",
      " [ 623 1260 3825]\n",
      " [ 447  628 9174]]\n",
      "====Iteration Multinomial 3 ====\n",
      "accuracy: 0.5806387025728301\n",
      "confusion matrix:\n",
      " [[1187  702 2239]\n",
      " [ 661 1351 3636]\n",
      " [ 453  687 9062]]\n",
      "====Iteration Multinomial 4 ====\n",
      "accuracy: 0.5803383722094304\n",
      "confusion matrix:\n",
      " [[1162  677 2212]\n",
      " [ 666 1331 3718]\n",
      " [ 447  664 9101]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    #print(f'{train_indices},{test_indices}')\n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    \n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    linear_model.fit(X_train,y_train)  # train object\n",
    "    y_hat = linear_model.predict(X_test) # get test set precitions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(f\"====Iteration Multinomial {iter_num} ====\")\n",
    "    print(f\"accuracy: {acc}\" )\n",
    "    print(f\"confusion matrix:\\n {conf}\")\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tried all solvers (‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’), liblinear --> gives the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "3    1\n",
       "4    0\n",
       "5    0\n",
       "6    1\n",
       "Name: above_average, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business_hot[\"above_average\"] = ny.where(df_business_hot[\"stars\"] > 3.5, 0, 1)\n",
    "y2 = df_business_hot[\"above_average\"]\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12469 94674 54688 ... 73487 63555 32288],[96690 98284 47916 ... 11102 63554 41631]\n",
      "====Iteration binomial 0 ====\n",
      "accuracy: 0.6886074682150365\n",
      "confusion matrix:\n",
      " [[7485 2816]\n",
      " [3405 6272]]\n",
      "[31147 66474 77168 ... 22976 52624 13079],[75090 33918 18365 ... 19861 23800   706]\n",
      "====Iteration binomial 1 ====\n",
      "accuracy: 0.6905596155771349\n",
      "confusion matrix:\n",
      " [[7637 2582]\n",
      " [3600 6159]]\n",
      "[ 8664 81834  3331 ... 41722 92419 69920],[78553 76033 87061 ... 69360 93809 47401]\n",
      "====Iteration binomial 2 ====\n",
      "accuracy: 0.6896586244869356\n",
      "confusion matrix:\n",
      " [[7487 2701]\n",
      " [3499 6291]]\n",
      "[56300 87165 45577 ... 31605 56718 50796],[23934   420 79881 ... 41419 24499  3861]\n",
      "====Iteration binomial 3 ====\n",
      "accuracy: 0.6863049354289719\n",
      "confusion matrix:\n",
      " [[7419 2751]\n",
      " [3516 6292]]\n",
      "[73373 86422 76661 ... 10940 46648   966],[40759 50430 85307 ... 77239 81788 25146]\n",
      "====Iteration binomial 4 ====\n",
      "accuracy: 0.6944639103013315\n",
      "confusion matrix:\n",
      " [[7608 2640]\n",
      " [3464 6266]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X2,y): \n",
    "    #print(f'{train_indices},{test_indices}')\n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y2.iloc[train_indices]\n",
    "    \n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y2.iloc[test_indices]\n",
    "    \n",
    "    linear_model.fit(X_train,y_train)  # train object\n",
    "    y_hat = linear_model.predict(X_test) # get test set precitions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(f\"====Iteration binomial {iter_num} ====\")\n",
    "    print(f\"accuracy: {acc}\" )\n",
    "    print(f\"confusion matrix:\\n {conf}\")\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'SGDClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-cba117b70a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Accuracy: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'SGDClassifier'"
     ]
    }
   ],
   "source": [
    "logistic = linear_model.SGDClassifier(n_jobs=-1, loss=\"log\")\n",
    "logistic.fit(x_train,y_train)\n",
    "\n",
    "y_pred = logistic.predict(x_test)\n",
    "print('Logistic Accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Logistic Precision: {:.2f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print('Logistic classification_report: ')\n",
    "class_report=metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stoichastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "svm = linear_model.SGDClassifier(n_jobs=-1, loss=\"hinge\")\n",
    "svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(x_test)\n",
    "print('SVM Accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('SVM Precision: {:.2f}'.format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print('SVM classification_report: ')\n",
    "class_report=metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear [too slow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "#following this beautiful guide\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POLY [too slow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(x_train)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Kernel (RBF) [too slow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(x_train)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Kernel [too slow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='sigmoid')\n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(x_train)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Advantages\t10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Feature Importance\t30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\t10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
